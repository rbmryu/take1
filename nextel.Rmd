---
title: "Nextel - Case"
author: "Rafael Meirelles"
output:
  html_document: default
  html_notebook: default
---

#Dependências

Importarndo dependências

```{r, message=FALSE, warning=FALSE}
library(readr)
library(dplyr)
library(ggplot2)
library(Metrics)
library(randomForest)
library(FNN)
library(xgboost)
```


Importando dados.

```{r, message=FALSE, warning=FALSE}
house_sales <- read_csv("~/Downloads/data_scientist_test/house_sales.csv")


```



#EDA - Análise Descritiva

Nesse gráfico (para análise ampliei o plot para melhor vizualização) tentaremos observar quais as varáveis possuem notável correlação a ser considerada  com a variável resposta (preço) e ainda eventuais variáveis que contém informações equivalentes. Em seguida a matriz de correlação é mostrada com o objetivo de quantificar essas relações:
```{r}
plot(house_sales)
cor(house_sales)
```


Observa-se que algumas variáveis referentes a especificações das propriedades em questão apresentam relação direta (correlação positiva) em níveis bastante expressivos como é o caso de número de quartos, número de banheiros , tamaho da casa, andares, presença de fonte e tamanho do porão  (0.30, 0.52, 0.70, 0.25, 0.27, 0.32 respectivamente). Tais variáveis tem sua relação com o preço da casa facilmente justificado e provavelmente são considerados pelo comprador no momento da compra. Observamos ainda que existe uma considerável correlação entre essas variáveis já que, por exemplo, casas com muitos quartos tendem a ter muitos banheiros. É importante considerar essa informação para evitar problemas como colinearidade durante a modelagem. Observe no exemplo a seguir como seria um ajuste do preço da propriedade pelo tamanho da mesma:

```{r}
ggplot(house_sales,aes(y=price,x=size_house)) + geom_point() + stat_smooth(method = "lm") + ggtitle("Ajuste de Regressão Linear: Preço da Casa ~ Tamanho da casa")
```


Fica claro que a variável consegue captar parte da variabilidade da variável resposta mas que ainda é necessário encontrar outras variáveis para complementar a análise.


O tamanho médio das casas vizinhas apesar de não ser uma informação específica da casa em questão, provavelmente revela muito sobre a região da casa e por isso mostra-se relevante, apresentando correlação de 0.58. Fica claro ainda que existe uma elevada homogeneidade entre as casas vizinhas já que o tamanho das casas vizinhas e o tamanho da casa em qustão possuem correlação na casa de 0.75. A seguir iremos tentar integrar essas duas variáveis em uma nofa feature.

Curiosamente a latitude apresenta uma correlação expressiva, na casa de 0.30. Sabendo que se tratam de propriedades nos Estados Unidos, isso significa que propriedades mais ao norte tendem a ser mais caras do que as mais ao sul.

As variáveis restantes não apresentaram correlação relevante (em módulo).


Seguem abaixo algumas variáveis potencialmente relevantes que podem ser criadas a partir da base fornecida:


**house_size_ratio**: Diante do fato de que tanto o tamanho casa quanto o tamanho das casas vizinhas se mostrou muito relacionado em termos de correlação com o preço da casa, uma hipótese é de que o a razão entre essas duas variáveis também se prove relevante (mostraria qual o tamanho do imóvel em questão quando comparado a)

**renovated**: 1 se a casa passou por renovação e 0 caso contrário

**renovated_or_built**: variável contém quantos anos se passaram desde a construção ou renovação, o que ocorreu mais recentemente (estamos aqui supondo que o ano corrente é 2016 já que os últimos registros de construção e renovação datam de 2015).


Abaixo criamos as variáveis citadas e perfomamos a normalização das variáveis para a utilização em alguns modelos específicos.
```{r}
house_sales = 
house_sales %>%
  mutate(house_size_ratio = size_house/avg_size_neighbor_houses,
         renovated = ifelse(renovation_date == 0, 0, 1),
         renovated_or_built = 2016 - ifelse(renovation_date == 0 , year_built, renovation_date))

norm_house_sales =  as.data.frame(cbind(house_sales[,1],scale(house_sales[,-1])))

cor(house_sales)[,"price"]
```

Observamos que as variáveis house_size_ratio, renovated e renovated_or_built apresentaram correlação de   0.30, 0.12 e -0.10. 
As variáveis relacionadas a renovação não revelam muito potencial preditivo mas é possível que integradas com as já existentes possam melhorar o desempenho preditivo.

#Modelagem

Agora que desenvolveu-se algum entendimento sobre o conjunto de dados, vamos seguir com a modelagem adequada.

Inicialmente vamos separar o conjunto de dados em conjundo de treinamento (85%)  e conjunto de teste (15%).

Em seguida realizaremos um ajuste base utilizando regressão linear para analisar o comportamento das variáveis e seguiremos com a utilização de modelos mais complexos como Random Forest, KNN e XGBoost.

Separando conjuntos de treino e teste:
```{r}
set.seed(1234)
training_samples = sample(nrow(house_sales),0.85*nrow(house_sales))
train = house_sales[training_samples,]
test = house_sales[-training_samples,]

norm_train = norm_house_sales[training_samples,]
norm_test = norm_house_sales[-training_samples,]
```



#Regressão Linear


Para este primeiro modelo iremos colocar todas as variáveis fornecidas juntamente com as criadas e analisar o desempenho. Obviamente seria necessário revisar quais variáveis realmente fazem sentido entrar no modelo e constatar quais podem ser colineares entre si. No entanto or questões de prazo e como o objetivo nesse momento é o desenvolvimento de um modelo base para podemos avaliar outros ajustes mais complexos, isso não será feito.
```{r}
ajuste_lm = lm(price~.,data=train)
summary(ajuste_lm)

predict_lm = predict(object = ajuste_lm, test)

print(paste("RMSE obtido no conjunto de teste COM REGRESSÃO LINEAR:",rmse(actual = test[,"price"],predict_lm)))

```

Observe que por meio da regressão linear e das variáveis utilizadas foi possível explicar 66% da variabilidade do preço dos imóveis, o que é um resultado bastante aceitável (e que obviamente pode ser melhorado). Nesse modelo base o RMSE obtido foi de 235624.5 no conjunto de testes.



#Random Forest

Observe agora os resultados obtidos por meio de um modelo de Floresta Aleatória:
```{r}
ajuste_rf = randomForest(price ~ .,
                      data=train, 
                      importance=TRUE, 
                      ntree=30)


predict_rf = predict(object = ajuste_rf, test)

print(paste("RMSE obtido no conjunto de teste RANDOM FOREST:",rmse(actual = test[,"price"],predict_rf)))




```

```{r}
varImpPlot(ajuste_rf,main = "Importância das Variáveis no ajuste de Random Forest")
```


Note que foi possível abaixar consideravelmente o RMSE, o que sugere que existem muitas relações não lineares que a regressão não foi capaz de captar (o que é reforçado pelo gráfico de importância das variáveis, que mostra como relevantes variáveis que a partir da EDA não pareciam possuir qualquer potencial).

#KNN

```{r}
train_knn = as.data.frame(norm_train[,2:19])
y_train_knn = as.data.frame(norm_train[,"price"])

test_knn = as.data.frame(norm_test[,2:19])

predict_knn_3 = knn.reg(train = train_knn,test = test_knn, y=y_train_knn,k = 3)
predict_knn_7 = knn.reg(train = train_knn,test = test_knn, y=y_train_knn,k = 7)
predict_knn_10 = knn.reg(train = train_knn,test = test_knn, y=y_train_knn,k = 10)
predict_knn_15 = knn.reg(train = train_knn,test = test_knn, y=y_train_knn,k = 15)


print(paste("RMSE obtido no conjunto de teste com KNN usando k = 3:",rmse(actual = test[,"price"],predict_knn_3$pred)))


print(paste("RMSE obtido no conjunto de teste com KNN usando k = 7:", rmse(actual = test[,"price"],predict_knn_7$pred)))


print(paste("RMSE obtido no conjunto de teste com KNN usando k = 10:",rmse(actual = test[,"price"],predict_knn_10$pred)))


print(paste("RMSE obtido no conjunto de teste com KNN usando k = 15:",rmse(actual = test[,"price"],predict_knn_15$pred)))



```

Observa-se que o melhor resultado obtido aconteceu com k = 7. Mas o desempenho ainda foi inferior ao obtido por meio de Random Forest.



#XGBoost

```{r}
ajuste_xgboost <- xgboost(data = as.matrix(norm_train[,2:19]), label = as.matrix(norm_train[,1]), max_depth = 3, eta = 0.6, nthread = 2, nrounds = 500, objective = "reg:linear")

```

```{r}
predict_xgboost = predict(object = ajuste_xgboost, as.matrix(norm_test))

print(paste("RMSE obtido no conjunto de teste XGBOOST:",rmse(actual = test[,"price"],predict_xgboost)))

```


Observa-se um grave problema de overfitting nesse ajuste que deve ser resolvido com parameter tunning, o que leva um tempo  para ser feito e fica para uma próxima versão.


#Resultados Consolidados

```{r}
resultados = cbind(real = test[,1],predict_lm,predict_rf,predict_knn = predict_knn_7$pred,predict_xgboost)

head(resultados)
```



#Conclusão

A partir da análise exploratória que foi realizada com o objetivo de compreender melhor a base de dados e da modelagem propriamente dita foi possível chegar a previsões muito boas do preço das propriedades.
Com mais tempo seria interessante utilizar de ferramentar como grid search para melhorar ainda mais o desempenho dos modelos e até estudar com mais calma os dados disponíveis.
Segue em anexo o csv dos resultados obtidos.

```{r}
write.csv(resultados,file = "/Users/rafaelzimba/Downloads/resultado.csv")
```









